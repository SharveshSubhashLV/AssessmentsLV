# -*- coding: utf-8 -*-
"""Classification_LAB2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xbV8s1ghCUb4s7bfrEwopwIKQDQKUWMh
"""

import pandas as pd
import numpy as nm
import matplotlib.pyplot as mtp
import pandas as pd
from sklearn.cluster import KMeans
from matplotlib import pyplot as plt
from sklearn.metrics import silhouette_score
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
import xgboost as xgb
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns

df = pd.read_csv("/content/mushroom.csv")
df.info()

df.head()

"""#Handling Null values"""

df.isna().sum()

df['stem-color']=df['stem-color'].fillna(df['stem-color'].mean())

df.isna().sum()

"""# Handling duplicate rows"""

duplicates = df.duplicated(keep=False)
df['dup_bool'] = duplicates
print(df[df['dup_bool'] == True].count())

df1 = df.drop_duplicates()

"""checking for duplicates again for verification"""

duplicates = df1.duplicated(keep=False)
df1['dup_bool'] = duplicates
print(df1[df1['dup_bool'] == True].count())

df1.drop('dup_bool',axis=1,inplace=True)
df1.head(1)

df1.info()

"""#EDA

**Univariate Analysis**
"""

# Plot histograms for numerical columns
for column in df1.select_dtypes(include=['float64', 'int64']).columns:
    plt.figure(figsize=(10, 5))
    sns.histplot(df[column])
    plt.title(f'Histogram of {column}')
    plt.xlabel(column)
    plt.ylabel('Frequency')
    plt.show()

"""**Removing outliers**

Checking for outliers
"""

# Identify numerical columns by data type
numerical_columns = df1.select_dtypes(include=['float64', 'int64']).columns

# Create a box plot for each numerical column
for column in numerical_columns:
    plt.figure(figsize=(10, 6))  # Set the figure size for better readability
    sns.boxplot(x=df1[column])
    plt.title(f'Box Plot of {column}')
    plt.xlabel(column)
    plt.show()

"""There are huge number of outliers in the columns

Removing outliers
"""

for col in df1.select_dtypes(["int","float"]):
  Q1 = df1[col].quantile(0.25)
  Q3 = df1[col].quantile(0.75)
  IQR = Q3 - Q1
  lower = Q1 - 1.5*IQR
  upper = Q3 + 1.5*IQR
  df1 = df1[df1[col]<upper]
  df1 = df1[df1[col]>=lower]

"""Verification of outlier removal"""

for column in numerical_columns:
    plt.figure(figsize=(10, 6))  # Set the figure size for better readability
    sns.boxplot(x=df1[column])
    plt.title(f'Box Plot of {column}')
    plt.xlabel(column)
    plt.show()

"""Though, there are very few outliers now, these are totally fine for classification

**Bivariable Analysis**
"""

# Generate scatter plots for pairs of numerical variables
numerical_columns = df1.select_dtypes(include=['float64', 'int64']).columns
for i in range(len(numerical_columns)):
    for j in range(i + 1, len(numerical_columns)):
        plt.figure(figsize=(10, 6))
        sns.scatterplot(data=df, x=numerical_columns[i], y=numerical_columns[j])
        plt.title(f'Scatter Plot between {numerical_columns[i]} and {numerical_columns[j]}')
        plt.show()

# Compute the correlation matrix for numerical variables
correlation_matrix = df1.corr(numeric_only=True)
print("Correlation matrix:\n", correlation_matrix)

# Plot the correlation matrix as a heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Heatmap of Correlation Matrix')
plt.show()

df1.info()

"""**No encoding needed**

#Feature Selection
"""

correlation_matrix = df1.corr(numeric_only=True)

"""Using the correlation matrix heat map and scatter plot for identifying the important features."""

#plotting the heatmap of correlation
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Heatmap of Correlation Matrix')
plt.show()

df1.columns

"""Clearly, all these columns are required for classification, as per the heatmap.

#Training and Test Data Splitting
"""

x = df1.drop('class',axis=1)
y = df1['class']

xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.3, random_state=42)

"""#Scaling"""

from sklearn.preprocessing import MinMaxScaler
mx = MinMaxScaler()
xtrain = mx.fit_transform(xtrain)
xtest = mx.transform(xtest)

"""#Model Building"""

xgb_clf = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)
xgb_clf.fit(xtrain, ytrain)
y_pred = xgb_clf.predict(xtest)
accuracy = accuracy_score(ytest, y_pred)
print("XGB Accuracy:", accuracy)
print(classification_report(ytest, y_pred))

"""#Model Evaluation"""

import seaborn as sns
conf_matrix = confusion_matrix(ytest, y_pred)
sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

"""#Insights from the model evaluation:
Clearly, we can see the model is performing good with a f1-score of 0.86 and accuracy of 87.6~ 88%
"""