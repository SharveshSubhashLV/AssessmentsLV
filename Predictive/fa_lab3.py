# -*- coding: utf-8 -*-
"""FA-LAB3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19ev5f6ATrV8BS50q3am3V3QdwOjHiMf0
"""

import pandas as pd
df = pd.read_csv("/content/customer_segmentation.csv")
df.info()

import pandas as pd
import numpy as nm
import matplotlib.pyplot as mtp
import pandas as pd
from sklearn.cluster import KMeans
from matplotlib import pyplot as plt

df.isna().sum()

df['Income'].fillna(df['Income'].mean(),inplace=True)
df.isna().sum()

x = df.select_dtypes(include=['float64', 'int64'])
x

x.drop('ID',axis=1,inplace=True)
x

"""Tried applying scaling initially but did not get a good elbow graph to identify the k value, but reiterated the process without scaling to get a good elbow graph"""

from sklearn.preprocessing import MinMaxScaler
m = MinMaxScaler()
x = m.fit_transform(x)

wcss_list= []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', random_state= 42)
    kmeans.fit(x)
    wcss_list.append(kmeans.inertia_)

plt.plot(range(1, 11), wcss_list)
plt.title('The Elobw Method Graph')
plt.xlabel('Number of clusters(k)')
plt.ylabel('wcss_list')
plt.show()

"""**Got a good Elbow Graph only when the features were not scaled** Here the K = 4"""

kmeans = KMeans(n_clusters=4, init='k-means++', random_state= 42)
y_predict= kmeans.fit_predict(x)

from sklearn.metrics import silhouette_score
kmeans.fit(x)
silhouette_score(x,kmeans.predict(x))

"""# Trying to improve the Silhouette_score"""

from sklearn.preprocessing import MinMaxScaler
m = MinMaxScaler()
x = m.fit_transform(x)

wcss_list= []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', random_state= 42)
    kmeans.fit(x)
    wcss_list.append(kmeans.inertia_)

plt.plot(range(1, 11), wcss_list)
plt.title('The Elobw Method Graph')
plt.xlabel('Number of clusters(k)')
plt.ylabel('wcss_list')
plt.show()

"""here, the number of clusters come out to be 6 or 7, as it is not sharp enough to identify, we will try both with 6 and 7, each once."""

kmeans = KMeans(n_clusters=6, init='k-means++', random_state= 42)
y_predict= kmeans.fit_predict(x)

from sklearn.metrics import silhouette_score
kmeans.fit(x)
silhouette_score(x,kmeans.predict(x))

kmeans = KMeans(n_clusters=7, init='k-means++', random_state= 42)
y_predict= kmeans.fit_predict(x)

from sklearn.metrics import silhouette_score
kmeans.fit(x)
silhouette_score(x,kmeans.predict(x))

"""**Clearly, here the scaling of dataset, did not improve in identifying the clusters, instead, without scaling, we got a better k value and a better Silhouette score. So, K = 4**

Getting x without scaling and then proceeding
"""

kmeans = KMeans(n_clusters=4, init='k-means++', random_state= 42)
y_predict= kmeans.fit_predict(x)

from sklearn.metrics import silhouette_score
kmeans.fit(x)
silhouette_score(x,kmeans.predict(x))

x.columns

df.shape

x.shape

df['Cluster'] = kmeans.labels_

labels = kmeans.labels_
plt.figure(figsize=(8, 6))
plt.scatter(df['ID'], df['Income'], c=df['Cluster'], cmap='viridis', s=50, alpha=0.5)
plt.title('K-means Clustering')
plt.xlabel('ID')
plt.ylabel('Income')
plt.legend()
plt.show()

"""**Clearly, the above graph shows the Customer segments as per their income levels as "High value customers", "Moderate Value customers","Average Value Customers" and "Low value Customers"**"""

#labels = kmeans.labels_
plt.figure(figsize=(8, 6))
plt.scatter(df['NumStorePurchases'], df['Income'], c=df['Cluster'], cmap='viridis', s=50, alpha=0.5)
plt.title('K-means Clustering')
plt.xlabel('NumStorePurchases')
plt.ylabel('Income')
plt.legend()
plt.show()

"""Shows the number of store purchasing tendency of different customer segments"""