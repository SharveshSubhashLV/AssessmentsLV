# -*- coding: utf-8 -*-
"""Regression_LAB1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wnnp1pIILHSVQA_5YwqNr2uLgQQ7Iidu
"""

import pandas as pd
from matplotlib import pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
import xgboost as xgb
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

df = pd.read_csv("/content/bengaluru_house_prices.csv")
df.info()

df.describe()

df.head()

"""#Handling Duplicate rows"""

duplicates = df.duplicated(keep=False)
df['dup_bool'] = duplicates
print(df[df['dup_bool'] == True].count())

df.drop('dup_bool',axis=1,inplace=True)
df.head(1)

duplicates = df.duplicated(keep=False)
df['dup_bool'] = duplicates
print(df[df['dup_bool'] == True].count())

df1 = df.drop_duplicates()

df1

df1.drop('dup_bool',axis=1,inplace=True)
df1.head(1)

df1.info()

"""#Handling Data types, formating and Null values"""

size = df1['size'].str.split(pat = ' ', expand = True)

size[0]

df1['size'] = pd.to_numeric(size[0],errors='coerce')
df1

df1['total_sqft'] = pd.to_numeric(df1['total_sqft'],errors='coerce')

df1.info()

df1.isna().sum()

#df['horsepower']=df['horsepower'].fillna(df['horsepower'].mean())
df1['size']=df1['size'].fillna(df1['size'].mean())
df1['balcony']= df1['balcony'].fillna(df1['balcony'].mean())
df1['bath']= df1['bath'].fillna(df1['bath'].mean())
df1['location'] = df1['location'].fillna(df1['location'].mode())

df1.isna().sum()

df1['total_sqft']= df1['total_sqft'].fillna(df1['total_sqft'].mean())

df1.info()

df1['society'].fillna(df1['society'].mode(),inplace=True)

df1.dropna(subset=['society'], inplace=True)

df1.info()

"""Clearly, got the non-null values and correct data types in all columns

#EDA

**Univariate Analysis**
"""

# Plot histograms for numerical columns
for column in df.select_dtypes(include=['float64', 'int64']).columns:
    plt.figure(figsize=(10, 5))
    sns.histplot(df[column])
    plt.title(f'Histogram of {column}')
    plt.xlabel(column)
    plt.ylabel('Frequency')
    plt.show()

# Plot bar charts for categorical columns
for column in df.select_dtypes(include=['object']).columns:
    plt.figure(figsize=(10, 5))
    df[column].value_counts().plot(kind='bar')
    plt.title(f'Bar Chart of {column}')
    plt.xlabel(column)
    plt.ylabel('Count')
    plt.show()

"""**Removing outliers**

Checking for outliers
"""

# Identify numerical columns by data type
numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns

# Create a box plot for each numerical column
for column in numerical_columns:
    plt.figure(figsize=(10, 6))  # Set the figure size for better readability
    sns.boxplot(x=df[column])
    plt.title(f'Box Plot of {column}')
    plt.xlabel(column)
    plt.show()

"""There are lot of outliers in price, but those are needed for for prediction, so we will remove the outliers in the number of bathrooms column.

Removing Outliers
"""

#for col in df.select_dtypes(["int","float"]):
Q1 = df1['bath'].quantile(0.25)
Q3 = df1['bath'].quantile(0.75)
IQR = Q3 - Q1
lower = Q1 - 1.5*IQR
upper = Q3 + 1.5*IQR
df1 = df1[df1['bath']<upper]
df = df1[df1['bath']>=lower]

"""Verification of outliers removal"""

for column in numerical_columns:
    plt.figure(figsize=(10, 6))  # Set the figure size for better readability
    sns.boxplot(x=df[column])
    plt.title(f'Box Plot of {column}')
    plt.xlabel(column)
    plt.show()

"""Clearly, outliers for bathrooms alone is removed.

**Bivariate Analysis**
"""

# Generate scatter plots for pairs of numerical variables
numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
for i in range(len(numerical_columns)):
    for j in range(i + 1, len(numerical_columns)):
        plt.figure(figsize=(10, 6))
        sns.scatterplot(data=df, x=numerical_columns[i], y=numerical_columns[j])
        plt.title(f'Scatter Plot between {numerical_columns[i]} and {numerical_columns[j]}')
        plt.show()

# Compute the correlation matrix for numerical variables
correlation_matrix = df1.corr(numeric_only=True)
print("Correlation matrix:\n", correlation_matrix)

# Plot the correlation matrix as a heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Heatmap of Correlation Matrix')
plt.show()

"""#Encoding"""

df1.columns

df1.info()

from sklearn.preprocessing import LabelEncoder
l = LabelEncoder()
df1['area_type'] = l.fit_transform(df1['area_type'])
df1['location'] = l.fit_transform(df1['location'])
df1['society'] = l.fit_transform(df1['society'])

df1.info()

"""#Feature Selection"""

correlation_matrix = df1.corr(numeric_only=True)
#plotting the heatmap of correlation
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Heatmap of Correlation Matrix')
plt.show()

"""By domain knowledge, we can clearly say that, availability of the house does not affect it's price, and from heatmap, we can see that society also does not matter, so removing these two alone."""

df2 = df1.drop(['society','availability'],axis=1)

correlation_matrix = df2.corr(numeric_only=True)
#plotting the heatmap of correlation
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Heatmap of Correlation Matrix')
plt.show()

"""#Training and Testing data splitting"""

x = df2.drop('price',axis=1)
y = df2['price']

xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.3, random_state=42)

"""#Scaling"""

from sklearn.preprocessing import MinMaxScaler
mx = MinMaxScaler()
xtrain = mx.fit_transform(xtrain)
xtest = mx.transform(xtest)

"""#Model Building"""

RF_reg = RandomForestRegressor()
RF_reg.fit(xtrain,ytrain)
y_pred = RF_reg.predict(xtest)

"""#Model Evaluation"""

MSE = mean_squared_error(ytest, y_pred)
RMSE = np.sqrt(MSE)
r2 = r2_score(ytest, y_pred)
print("Random Forest \nMSE:", MSE)
print("RMSE:", RMSE)
print("R2 score:", r2)